{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXURLEhqSR4v",
        "outputId": "4222df93-01ab-49d7-fcb3-4464a2182dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pickle.load(open('drive/MyDrive/oliverjawclench1.pk1' , 'rb'))\n",
        "data2 = pickle.load(open('drive/MyDrive/oliverjawclench2.pk1' , 'rb'))\n",
        "data3 = pickle.load(open('drive/MyDrive/HarshFilteredData.pk1' , 'rb'))\n",
        "data4 = pickle.load(open('drive/MyDrive/AyaanFilteredData.pk1' , 'rb'))\n",
        "data5 = pickle.load(open('drive/MyDrive/AyaanFilteredData2.pk1' , 'rb'))"
      ],
      "metadata": {
        "id": "Zm-Da-ZYSYkm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "trainingData = [[],[],[],[],[],[],[],[],[]]\n",
        "trainingDataSegmented = [[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]]]\n",
        "\n",
        "num0 = 0\n",
        "num1 = 0\n",
        "num2 = 0\n",
        "\n",
        "for i in range(0,9):\n",
        "  trainingData[i] = list(data1[i]) + list(data2[i]) + list(data4[i]) + list(data5[i])\n",
        "  for j in range(0, len(trainingData[i])):\n",
        "    if j // 250 >= len(trainingDataSegmented[i]):\n",
        "      #print(num1, num0)\n",
        "      trainingDataSegmented[i].append([])\n",
        "      if i == 8:\n",
        "        if max(num0, num1, num2) == num2:\n",
        "          trainingDataSegmented[i][(j // 250)-1].append(2)\n",
        "        elif max(num0, num1, num2) == num1:\n",
        "          trainingDataSegmented[i][(j // 250)-1].append(1)\n",
        "        else:\n",
        "          trainingDataSegmented[i][(j // 250)-1].append(0)\n",
        "        num0 = 0\n",
        "        num1 = 0\n",
        "        num2 = 0\n",
        "    if i != 8:\n",
        "      trainingDataSegmented[i][j // 250].append(trainingData[i][j])\n",
        "    else:\n",
        "      if trainingData[i][j] == 2:\n",
        "        num2+=1\n",
        "      elif trainingData[i][j] == 1:\n",
        "        #print(\"hi\")\n",
        "        num1+=1\n",
        "      elif trainingData[i][j] == 0:\n",
        "        num0+=1\n",
        "  trainingDataSegmented[i].pop()\n",
        "\n",
        "\n",
        "x = np.array([np.array(trainingDataSegmented[0]), np.array(trainingDataSegmented[1]), np.array(trainingDataSegmented[2]), np.array(trainingDataSegmented[3]), np.array(trainingDataSegmented[4]), np.array(trainingDataSegmented[5]), np.array(trainingDataSegmented[6]), np.array(trainingDataSegmented[7])])\n",
        "x = np.swapaxes(x, 0, 1)\n",
        "\n",
        "y = np.array(trainingDataSegmented[8])\n",
        "tmp = []\n",
        "for i in range(y.shape[0]): # This loop turns the sample readings into seconds\n",
        "  tmp.append(y[i][0])\n",
        "y = np.array(tmp)\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "# x sample\n",
        "# y 0 or 1\n",
        "\n",
        "# now we need to \"flatten\" the 3d array into a 2d one\n",
        "xsamples, x1, x2 = x.shape\n",
        "x = x.reshape((xsamples,x1*x2))\n",
        "\n",
        "print(x.shape, y.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=109) # 70% training and 30% test\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybqHItShSZY7",
        "outputId": "1b185b89-2e8f-4800-8b23-6f4835d5cb65"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3008, 2000) (3008,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "#scaler = MinMaxScaler()\n",
        "#scaler = RobustScaler()\n",
        "X_train_scale = scaler.fit_transform(X_train)\n",
        "X_test_scale = scaler.transform(X_test)\n",
        "\n",
        "# X_train_scale = X_train\n",
        "# X_test_scale = X_test\n",
        "\n",
        "X_train_scale.mean(axis=0)\n",
        "#X_train_scale.std(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wANwO36Sawi",
        "outputId": "885fea39-d294-40bc-d94f-6eb5810f03b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.22992335e-17, -1.06275506e-17, -2.53689917e-17, ...,\n",
              "        4.27739132e-17, -6.90922642e-18,  2.32065620e-18])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import svm model\n",
        "from sklearn import svm\n",
        "from sklearn import linear_model\n",
        "\n",
        "#Create a svm Classifier\n",
        "classifier = svm.SVC(kernel='rbf', C=2)\n",
        "#classifier = svm.LinearSVC(dual=False)\n",
        "#classifier = linear_model.SGDClassifier(loss='hinge')\n",
        "\n",
        "#Train the model using the training sets\n",
        "classifier.fit(X_train_scale, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = classifier.predict(X_test_scale)"
      ],
      "metadata": {
        "id": "m9VzlasOSeJD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80vZC-BKSfIC",
        "outputId": "1189d2c5-abb4-4abf-d366-dadcc2721dea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8615725359911407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(classifier, open('emgmodel.pk1', 'wb'))"
      ],
      "metadata": {
        "id": "YyC4zsowSf-r"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}