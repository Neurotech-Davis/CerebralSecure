{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyINpaH8WBzg",
        "outputId": "1ec3a173-5cc6-45d7-bddd-b8869793cc70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alexaData = pickle.load(open('drive/MyDrive/AlexaFilteredData.pk1' , 'rb'))\n",
        "angelData = pickle.load(open('drive/MyDrive/AngelFilteredData.pk1' , 'rb'))\n",
        "angelData2 = pickle.load(open('drive/MyDrive/AngelFilteredData2.pk1' , 'rb'))\n",
        "ashaniData = pickle.load(open('drive/MyDrive/AshaniFilteredData.pk1' , 'rb'))"
      ],
      "metadata": {
        "id": "l8P_0CCydvIl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "trainingData = [[],[],[],[],[],[],[],[],[]]\n",
        "trainingDataSegmented = [[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]]]\n",
        "\n",
        "num0 = 0\n",
        "num1 = 0\n",
        "\n",
        "for i in range(0,9):\n",
        "  #trainingData[i] = list(alexaData[i]) + list(angelData[i]) + list(angelData2[i]) + list(ashaniData[i])\n",
        "  trainingData[i] = list(alexaData[i]) + list(ashaniData[i])\n",
        "  for j in range(0, len(trainingData[i])):\n",
        "    if j // 250 >= len(trainingDataSegmented[i]):\n",
        "      #print(num1, num0)\n",
        "      trainingDataSegmented[i].append([])\n",
        "      if i == 8:\n",
        "        if num1 < num0:\n",
        "          #print(\"appending 0\")\n",
        "          trainingDataSegmented[i][(j // 250)-1].append(0)\n",
        "        else:\n",
        "          #print(\"appending 1\")\n",
        "          trainingDataSegmented[i][(j // 250)-1].append(1)\n",
        "        num0 = 0\n",
        "        num1 = 0\n",
        "    if i != 8:\n",
        "      trainingDataSegmented[i][j // 250].append(trainingData[i][j])\n",
        "    else:\n",
        "      if trainingData[i][j] == 1:\n",
        "        #print(\"hi\")\n",
        "        num1+=1\n",
        "      elif trainingData[i][j] == 0:\n",
        "        num0+=1\n",
        "  trainingDataSegmented[i].pop()\n",
        "\n",
        "\n",
        "x = np.array([np.array(trainingDataSegmented[0]), np.array(trainingDataSegmented[1]), np.array(trainingDataSegmented[2]), np.array(trainingDataSegmented[3]), np.array(trainingDataSegmented[4]), np.array(trainingDataSegmented[5]), np.array(trainingDataSegmented[6]), np.array(trainingDataSegmented[7])])\n",
        "x = np.swapaxes(x, 0, 1)\n",
        "\n",
        "y = np.array(trainingDataSegmented[8])\n",
        "tmp = []\n",
        "for i in range(y.shape[0]): # This loop turns the sample readings into seconds\n",
        "  tmp.append(y[i][0])\n",
        "y = np.array(tmp)\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "# x sample\n",
        "# y 0 or 1\n",
        "\n",
        "# now we need to \"flatten\" the 3d array into a 2d one\n",
        "xsamples, x1, x2 = x.shape\n",
        "x = x.reshape((xsamples,x1*x2))\n",
        "\n",
        "print(x.shape, y.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=109) # 70% training and 30% test\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NzTPhOAflMx",
        "outputId": "ba5ceec4-dfcb-4058-c041-6ef85d5c3701"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2768, 2000) (2768,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.02594768, -0.03460123, -0.12587811, ...,  0.03362431,\n",
              "        0.02650186, -0.05313976])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scaler = StandardScaler()\n",
        "# scaler = MinMaxScaler()\n",
        "# scaler = RobustScaler()\n",
        "# X_train_scale = scaler.fit_transform(X_train)\n",
        "# X_test_scale = scaler.transform(X_test)\n",
        "\n",
        "X_train_scale = X_train\n",
        "X_test_scale = X_test\n",
        "\n",
        "X_train_scale.mean(axis=0)\n",
        "#X_train_scale.std(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ifpz7ukDMdY",
        "outputId": "673593e6-e6fb-4821-d6ef-070292f75505"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.02594768, -0.03460123, -0.12587811, ...,  0.03362431,\n",
              "        0.02650186, -0.05313976])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import svm model\n",
        "from sklearn import svm\n",
        "from sklearn import linear_model\n",
        "\n",
        "#Create a svm Classifier\n",
        "classifier = svm.SVC(kernel='rbf', C=2)\n",
        "#classifier = svm.LinearSVC(dual=False)\n",
        "#classifier = linear_model.SGDClassifier(loss='squared_epsilon_insensitive')\n",
        "\n",
        "#Train the model using the training sets\n",
        "classifier.fit(X_train_scale, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = classifier.predict(X_test_scale)"
      ],
      "metadata": {
        "id": "Lg5k1wlDgJUE"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV6TaBg_gMFJ",
        "outputId": "526e6a49-705f-4b61-f907-94fdef31ca3c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7509025270758123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(classifier, open('focusmodel.pk1', 'wb'))"
      ],
      "metadata": {
        "id": "B23_-bd2Iku5"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}